{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from geopy.distance import great_circle\n",
    "\n",
    "def clean_html(df):\n",
    "    df.replace({r'<.*?>': ''}, regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bejing Pollution Data Preparation  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "def parse(x):\n",
    "\treturn datetime.strptime(x, '%Y %m %d %H')\n",
    "dataset = read_csv('HurricaneData/PRSA_data_2010.1.1-2014.12.31.csv',  parse_dates = [['year', 'month', 'day', 'hour']], index_col=0, date_parser=parse)\n",
    "dataset.drop('No', axis=1, inplace=True)\n",
    "# manually specify column names\n",
    "dataset.columns = ['pollution', 'dew', 'temp', 'press', 'wnd_dir', 'wnd_spd', 'snow', 'rain']\n",
    "dataset.index.name = 'date'\n",
    "# mark all NA values with 0\n",
    "dataset['pollution'].fillna(0, inplace=True)\n",
    "# drop the first 24 hours\n",
    "dataset = dataset[24:]\n",
    "# summarize first 5 rows\n",
    "print(dataset.head(5))\n",
    "# save to file\n",
    "dataset.to_csv('HurricaneData/Preprocessed/pollution.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Texas, Houston weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "def parse(x):\n",
    "\treturn datetime.strptime(x, '%Y-%m-%d')\n",
    "dataset = read_csv('HurricaneData/houston.csv', index_col=0)\n",
    "print(\"Original dataset:\")\n",
    "print(dataset.head(5))\n",
    "dataset.drop(dataset.columns[0], axis=1, inplace=True)\n",
    "dataset.index.name = 'Date'\n",
    "\n",
    "# mark all NA values with 0\n",
    "dataset.fillna(0, inplace=True)\n",
    "\n",
    "clean_html(dataset)\n",
    "\n",
    "# summarize first 5 rows\n",
    "print(\"Processed dataset:\")\n",
    "print(dataset.head(5))\n",
    "# save to file\n",
    "dataset.to_csv('HurricaneData/Preprocessed/houston.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houston_lat_lon = (29.76043, -95.36980)\n",
    "\n",
    "def location_filter(x):\n",
    "    distance = great_circle((x['Latitude'], x['Longitude']), houston_lat_lon).miles\n",
    "    return distance < 700\n",
    "    \n",
    "dataset = read_csv('HurricaneData/atlantic.csv', index_col=0)\n",
    "print(\"Original dataset:\")\n",
    "print(dataset.head(5))\n",
    "dataset.drop(dataset.columns[0], axis=1, inplace=True)\n",
    "dataset.index.name = 'Date'\n",
    "\n",
    "# mark all NA values with 0\n",
    "dataset.fillna(0, inplace=True)\n",
    "\n",
    "dataset['Latitude'].replace({r'[^0-9]': ''}, regex=True, inplace=True)\n",
    "dataset['Longitude'].replace({r'[^0-9]': ''}, regex=True, inplace=True)\n",
    "dataset['Latitude'] = pd.to_numeric(dataset['Latitude'], downcast='float')\n",
    "dataset['Longitude'] = pd.to_numeric(dataset['Longitude'], downcast='float')\n",
    "dataset = dataset[dataset.apply(location_filter, axis=1)]\n",
    "\n",
    "# summarize first 5 rows\n",
    "print(\"Processed dataset:\")\n",
    "print(dataset.head(5))\n",
    "\n",
    "# save to file\n",
    "dataset.to_csv('HurricaneData/Preprocessed/hurdat_houston.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
