{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hurricane Prediction\n",
    "\n",
    "## Intro\n",
    "\n",
    "The idea is to predict hurricane entry based on a set of weather conditions that are measured in the USA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.noise import GaussianNoise, GaussianDropout\n",
    "from datetime import datetime, timedelta\n",
    "from IPython.display import clear_output\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pyowm\n",
    "import yaml\n",
    "import time\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('config.yml') as f:\n",
    "    # use safe_load instead load\n",
    "    config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def render_plots_numbers(data):\n",
    "    values = data.values\n",
    "    cols_to_plot = [col for col in range(1, len(data.columns)) if type(values[0, col]) != str]\n",
    "    pyplot.figure(figsize=(10, len(cols_to_plot) * 1.2))\n",
    "    i = 1\n",
    "    for group in cols_to_plot:\n",
    "        pyplot.subplot(len(cols_to_plot), 1, i)\n",
    "        pyplot.plot(values[:, group])\n",
    "        pyplot.title(data.columns[group], y=1, loc='right')\n",
    "        i += 1\n",
    "    pyplot.tight_layout(h_pad=1)\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "houston_weather = read_csv('HurricaneData/Preprocessed/houston.csv', index_col=0)\n",
    "hurdat_houston = read_csv('HurricaneData/Preprocessed/hurdat_houston.csv', index_col=0)\n",
    "\n",
    "houston_weather.index = pd.to_datetime(houston_weather.index)\n",
    "hurdat_houston.index = pd.to_datetime(hurdat_houston.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hurdat_houston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "render_plots_numbers(hurdat_houston)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "houston_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "render_plots_numbers(houston_weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "houston_to_supervise = houston_weather.loc[:, ['Events', 'Max.TemperatureF', 'Max.Dew.PointF', 'Max.Humidity', 'Max.Wind.SpeedMPH', 'Max.Sea.Level.PressureIn']]\n",
    "houston_to_supervise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Hurricane_Started' in houston_to_supervise:\n",
    "    del houston_to_supervise['Hurricane_Started']\n",
    "houston_to_supervise.insert(len(houston_to_supervise.columns), 'Hurricane_Started', 0)\n",
    "hurricane_started = np.zeros(len(houston_to_supervise.index))\n",
    "date_range = timedelta(days=2)\n",
    "for i, row in enumerate(houston_to_supervise.itertuples()):\n",
    "    start_date = row[0] - date_range\n",
    "    end_date = row[0] + date_range\n",
    "    mask = (hurdat_houston.index > start_date) & (hurdat_houston.index <= end_date)\n",
    "    found_hurricane = len(hurdat_houston[mask].index) > 0\n",
    "    if found_hurricane:\n",
    "        hurricane_started[i] = 1\n",
    "hurricane_started.shape, houston_to_supervise.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = houston_to_supervise.values\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "values[:,0] = encoder.fit_transform(values[:,0])\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "values[:,1] = encoder.fit_transform(values[:,1])\n",
    "\n",
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, dataset_cols, n_in=1, n_out=1, dropnan=True):\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t\tnames += [('%s(t-%d)' % (dataset_cols[j], i)) for j in range(n_vars)]\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [('%s(t)' % (dataset_cols[j])) for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [('%s(t+%d)' % (dataset_cols[j], i)) for j in range(n_vars)]\n",
    "\t# put it all together\n",
    "\tagg = concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure all data is float\n",
    "values = values.astype('float32')\n",
    "\n",
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)\n",
    "# frame as supervised learning\n",
    "# todo: increase input or forecast to do > 1 day forecast\n",
    "reframed = series_to_supervised(scaled, houston_to_supervise.columns, 1, 1)\n",
    "\n",
    "# drop columns we don't want to predict\n",
    "reframed.drop(reframed.loc[:, 'Events(t)' : 'Max.Humidity(t)'].head(0).columns, axis=1, inplace=True)\n",
    "reframed.drop(reframed.loc[:, ['Max.Sea.Level.PressureIn(t)']].head(0).columns, axis=1, inplace=True)\n",
    "\n",
    "print(reframed.head(), reframed.shape, values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test sets\n",
    "train_percent = 0.5\n",
    "train_amount = math.floor(len(reframed.values) * train_percent)\n",
    "train = reframed.values[:train_amount, :]\n",
    "test = reframed.values[train_amount:, :]\n",
    "# split into input and outputs\n",
    "train_X, train_y = train[:, :-1], train[:, -2:]\n",
    "test_X, test_y = test[:, :-1], test[:, -2:]\n",
    "\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# design network\n",
    "model = Sequential()\n",
    "model.add(GaussianNoise(0.5, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(LSTM(1, return_sequences=False))\n",
    "model.add(GaussianDropout(rate=0.5))\n",
    "model.add(Dense(2))\n",
    "model.compile(loss='mae', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "while True:\n",
    "    # fit network\n",
    "    history = model.fit(train_X, train_y, epochs=10, batch_size=72, validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
    "    \n",
    "    # Clear the screen so we can see the charts\n",
    "    clear_output()\n",
    "    \n",
    "    # plot history\n",
    "    pyplot.plot(history.history['loss'], label='train')\n",
    "    pyplot.plot(history.history['val_loss'], label='test')\n",
    "    pyplot.legend()\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "owm_headers = ['timestamp', 'Max.TemperatureF', 'Min.TemperatureF', 'status_short', 'status', 'wind_speed', 'wind_dir', 'cloud_coverage', 'humidity', 'pressure', 'sea_level', 'rain', 'snow']\n",
    "owm_data_path = 'HurricaneData/owm_houston.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weather_row_to_pandas(rows):\n",
    "    def val_by_name(r, name):\n",
    "        return r[owm_headers.index(name)]\n",
    "    \n",
    "    data = []\n",
    "    index = []\n",
    "    for r in rows:\n",
    "        index.append(r[0])\n",
    "        data.append([0, val_by_name(r, 'Max.TemperatureF'), 0, val_by_name(r, 'humidity'),\n",
    "                     val_by_name(r, 'wind_speed'), val_by_name(r, 'sea_level')])\n",
    "    return (pd.DataFrame(data=data,\n",
    "                      index=index,\n",
    "                      columns=['Events', 'Max.TemperatureF', 'Max.Dew.PointF', 'Max.Humidity',\n",
    "                               'Max.Wind.SpeedMPH', 'Max.Sea.Level.PressureIn']))\n",
    "\n",
    "if os.path.isfile(owm_data_path):\n",
    "    with open(owm_data_path, 'r') as csv_file:\n",
    "        reader = csv.reader(csv_file,  delimiter=';',\n",
    "                            quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "        next(reader) # skip header\n",
    "        print(weather_row_to_pandas(reader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "while True:\n",
    "    owm = pyowm.OWM(config['owm_api_key'])  # You MUST provide a valid API key\n",
    "    fc = owm.daily_forecast('Texas')\n",
    "    f = fc.get_forecast()\n",
    "    file_exists = os.path.isfile(csv_path)\n",
    "    \n",
    "    weather_rows = []\n",
    "    for w in f.get_weathers():\n",
    "        rain = w.get_rain()\n",
    "        snow = w.get_snow()\n",
    "        temp = w.get_temperature(unit='fahrenheit')\n",
    "        pres = w.get_pressure()\n",
    "        wind = w.get_wind()\n",
    "        weather_row = [w.get_reference_time(), temp.get('max', ''), temp.get('min', ''), w.get_status(), w.get_detailed_status(), wind.get('speed', ''), wind.get('deg', ''), w.get_clouds(), w.get_humidity(), pres.get('press', ''), pres.get('sea_level', ''), rain.get('all', ''), snow.get('all', '')]\n",
    "        weather_rows.append(weather_row)\n",
    "    \n",
    "    weather_row_to_pandas(weather_rows)        \n",
    "    time.sleep(60 * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make a prediction\n",
    "yhat = model.predict(test_X)\n",
    "\n",
    "# invert scaling for forecast\n",
    "test_X_reshaped = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "inv_yhat = concatenate((yhat, test_X_reshaped[:, 1:]), axis=1)\n",
    "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "inv_yhat = inv_yhat[:,0]\n",
    "\n",
    "# invert scaling for actual\n",
    "test_y_reshaped = test_y.reshape((len(test_y), 1))\n",
    "inv_y = concatenate((test_y_reshaped, test_X_reshaped[:, 1:]), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:,0]\n",
    "\n",
    "pyplot.figure(figsize=(10, 10))\n",
    "i = 1\n",
    "pyplot.subplot(len(groups) + 1, 1, i)\n",
    "pyplot.plot(inv_yhat)\n",
    "pyplot.title('pollution_predicted', y=1, loc='right')\n",
    "i += 1\n",
    "for group in groups:\n",
    "\tpyplot.subplot(len(groups) + 1, 1, i)\n",
    "\tpyplot.plot(test_X_reshaped[:, group])\n",
    "\tpyplot.title(dataset.columns[group], y=1, loc='right')\n",
    "\ti += 1\n",
    "\n",
    "pyplot.tight_layout(h_pad=1)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
